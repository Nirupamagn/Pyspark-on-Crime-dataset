# -*- coding: utf-8 -*-
"""3_logistic regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m3UpCpGJ5Z9vQLwtAj-4i6EMifQ41dVf
"""

from pyspark.sql import SparkSession
from pyspark.ml.feature import StringIndexer, VectorAssembler
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

from google.colab import files

# Upload the file
uploaded = files.upload()

for filename in uploaded.keys():
    csv_file = filename

spark = SparkSession.builder.appName("CrimeClassification").getOrCreate()

crime_df = spark.read.csv(csv_file, header=True, inferSchema=True)

crime_df = crime_df.select("date_reported", "date_occurred", "area", "crime_code", "status")

crime_df = crime_df.dropna()

indexer = StringIndexer(inputCol="status", outputCol="label")
crime_df = indexer.fit(crime_df).transform(crime_df)

assembler = VectorAssembler(
       inputCols=["area", "crime_code"],
       outputCol="features"
)
crime_df = assembler.transform(crime_df)

train_data, test_data = crime_df.randomSplit([0.8, 0.2], seed=42)

lr = LogisticRegression(featuresCol="features", labelCol="label")
model = lr.fit(train_data)

predictions = model.transform(test_data)

evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
accuracy = evaluator.evaluate(predictions)

last_10_rows = predictions.select("features", "label", "prediction").tail(10)
for row in last_10_rows:
    print(row)
print(f"Model Accuracy: {accuracy}")