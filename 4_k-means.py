# -*- coding: utf-8 -*-
"""4_KNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_RInxuZMXBucuygKjmlva9anFflI-IXE
"""

from google.colab import files
from pyspark.sql import SparkSession
from pyspark.ml.feature import StringIndexer, VectorAssembler
from pyspark.ml.clustering import KMeans

uploaded = files.upload()

for filename in uploaded.keys():
    csv_file = filename

spark = SparkSession.builder.appName("CrimeClustering").getOrCreate()

crime_df = spark.read.csv(csv_file, header=True, inferSchema=True)

crime_df = crime_df.select("crime_code", "status")

crime_df = crime_df.dropna()

indexer = StringIndexer(inputCol="status", outputCol="status_index")
crime_df = indexer.fit(crime_df).transform(crime_df)

assembler = VectorAssembler(
    inputCols=["crime_code", "status_index"],
    outputCol="features"
)
crime_df = assembler.transform(crime_df)

kmeans = KMeans(featuresCol="features", k=5, seed=42)
model = kmeans.fit(crime_df)

predictions = model.transform(crime_df)

predictions.select("crime_code", "status", "prediction").show(10)

from pyspark.ml.evaluation import ClusteringEvaluator
evaluator = ClusteringEvaluator(predictionCol="prediction", featuresCol="features", metricName="silhouette", distanceMeasure="squaredEuclidean")
silhouette = evaluator.evaluate(predictions)
print(f"Silhouette Score: {silhouette}")

